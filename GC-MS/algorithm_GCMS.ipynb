{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name:</th>\n",
       "      <th>InChIKey:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10,11-(4',5'-Phthaloyl-4',5'-diazacyclohexano)...</td>\n",
       "      <td>PJHMULXOUYBGON-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acetic acid, 1-acetoxy-10a,12a-dimethyl-5-oxo-...</td>\n",
       "      <td>ICFHFOMKTZRYEJ-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10aR)-6-Oxodecahydro-7,10-methanopyrido[1,2-a...</td>\n",
       "      <td>XGDWTAWUJCJBON-XOJNLIDHSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,10a-Dihydroxy-4,4,7,11b-tetramethyl-1,2,3,4a...</td>\n",
       "      <td>KVYGWNFQSFDUEL-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Name:  \\\n",
       "0  10,11-(4',5'-Phthaloyl-4',5'-diazacyclohexano)...   \n",
       "1  Acetic acid, 1-acetoxy-10a,12a-dimethyl-5-oxo-...   \n",
       "2  (10aR)-6-Oxodecahydro-7,10-methanopyrido[1,2-a...   \n",
       "3  1,10a-Dihydroxy-4,4,7,11b-tetramethyl-1,2,3,4a...   \n",
       "4                                                NaN   \n",
       "\n",
       "                     InChIKey:  \n",
       "0  PJHMULXOUYBGON-UHFFFAOYSA-N  \n",
       "1  ICFHFOMKTZRYEJ-UHFFFAOYSA-N  \n",
       "2  XGDWTAWUJCJBON-XOJNLIDHSA-N  \n",
       "3  KVYGWNFQSFDUEL-UHFFFAOYSA-N  \n",
       "4                          NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_3_output_folder = 'algorithm_output'\n",
    "retrieved_filename = 'retrieved_result.csv'\n",
    "extraction_keys_filename = 'environstd_inchi.csv'\n",
    "extraction_keys_file_encoding = 'ANSI'\n",
    "\n",
    "foldername = 'GCMS_output' # this is the forlder where the cleaned data is stored\n",
    "cleaned_folder_name = 'cleaned_data'\n",
    "\n",
    "read_folder = os.path.join(os.getcwd(), foldername)\n",
    "cleaned_folder = os.path.join(read_folder, cleaned_folder_name) # folder that we will be reading data from\n",
    "\n",
    "df = pd.read_csv(os.path.join(os.getcwd(), extraction_keys_filename), encoding=extraction_keys_file_encoding)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inchikey_list = df['InChIKey:'].str.strip().array\n",
    "name_list = df['Name:'].str.strip().array\n",
    "columns_to_be_included = [\n",
    "    'Name:', \n",
    "    'Formula:',\n",
    "    'MW:',\n",
    "    'NIST#:',\n",
    "    'InChIKey:', \n",
    "    'MS2:',\n",
    "    'Score:',\n",
    "    'EstRI', #try to extract the 2 RI values in the text\n",
    "    'PredRI'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algorithm part from algorithm3\n",
    "##clean up the mw to valide python datatype\n",
    "#work on 2021 July23\n",
    "def clean_MW(df):\n",
    "# def clean_precursormz(df):\n",
    "    inchikeys = df['InChIKey:'].unique().tolist()\n",
    "    for inchikey in inchikeys:\n",
    "        curr_precursormz = df.loc[df['InChIKey:'] == inchikey, 'MW:'].iloc[0]\n",
    "        try:\n",
    "            curr_precursormz = ast.literal_eval(curr_precursormz)\n",
    "            df.loc[df['InChIKey:'] == inchikey, ['MW:']] = curr_precursormz[0]\n",
    "        except TypeError:\n",
    "            curr_precursormz = float(curr_precursormz)\n",
    "            df.loc[df['InChIKey:'] == inchikey, ['MW:']] = curr_precursormz\n",
    "        except ValueError:\n",
    "            curr_precursormz = float(curr_precursormz)\n",
    "            df.loc[df['InChIKey:'] == inchikey, ['MW:']] = curr_precursormz\n",
    "    return df\n",
    "\n",
    "def filter_small_score(df, threshold):\n",
    "    return df[df['Score:'] >= threshold]\n",
    "\n",
    "def retrieve_ms2_dict(df): \n",
    "    ms2_dict = pd.Series(df['Score:'].array, index=df['MS2:']).to_dict()\n",
    "    return ms2_dict\n",
    "\n",
    "def append_to_list(df):\n",
    "    output_dict = {}\n",
    "    for i, item in df['Name:'].items():\n",
    "        if 'Name:' in output_dict.keys():\n",
    "            if item not in output_dict['Name:']:\n",
    "                if type(output_dict['Name:']) == list:\n",
    "                    if type(item) == list:\n",
    "                        output_dict['Name:'] += item\n",
    "                    else:\n",
    "                        output_dict['Name:'].append(item)\n",
    "                else:\n",
    "                    if type(item) == list:\n",
    "                        output_dict['Name:'] = item.append(output_dict['Name:'])\n",
    "                    else:\n",
    "                        output_dict['Name:'] = [output_dict['Name:'], item]\n",
    "        else:\n",
    "            output_dict['Name:'] = item\n",
    "    return pd.Series(output_dict)\n",
    "\n",
    "\n",
    "#set search range for the similar product ms\n",
    "search_range = 1\n",
    "output_folder = os.path.join(os.getcwd(), algo_3_output_folder, 'non_combined_output')\n",
    "\n",
    "if not (os.path.exists(output_folder)):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "## get list of csv file names\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cleaned_folder)\n",
    "listdir = glob.glob('*.csv')\n",
    "os.chdir(cwd)\n",
    "\n",
    "threshold = 30\n",
    "\n",
    "#from below, precursormz === mw  \n",
    "\n",
    "for filename in tqdm(listdir):\n",
    "#     if filename == '74_cleaned.csv':\n",
    "        cleaned_file = os.path.join(cleaned_folder, filename)\n",
    "        precursormz = int(filename.split('_')[0])\n",
    "        raw_file = os.path.join(read_folder, str(precursormz) + '.csv')\n",
    "        raw_interfering_file = os.path.join(read_folder, str(precursormz - 1) + '.csv')\n",
    "        \n",
    "        cleaned_df = pd.read_csv(cleaned_file)\n",
    "        cleaned_df = filter_small_score(cleaned_df, threshold)\n",
    "        cleaned_df.sort_values(by=['InChIKey:', 'MS2:'], inplace=True)\n",
    "        cleaned_df = clean_MW(cleaned_df) #clean up the precursor ion or the mw, make it into python datatype\n",
    "        \n",
    "        raw_df = pd.read_csv(raw_file)\n",
    "        raw_df = raw_df[columns_to_be_included]\n",
    "        raw_df = filter_small_score(raw_df, threshold)\n",
    "        raw_df.sort_values(by=['InChIKey:', 'MS2:'], inplace=True)\n",
    "        raw_df = clean_MW(raw_df)\n",
    "\n",
    "        try:\n",
    "            raw_interfering_df = pd.read_csv(raw_interfering_file)\n",
    "            raw_interfering_df = filter_small_score(raw_interfering_df, threshold)\n",
    "            raw_interfering_df = raw_interfering_df[columns_to_be_included]    \n",
    "        except FileNotFoundError:\n",
    "            raw_interfering_df = pd.DataFrame()\n",
    "\n",
    "        output_file = os.path.join(output_folder, str(precursormz) + '_algo3.csv')\n",
    "        inchikeys = cleaned_df['InChIKey:'].unique().tolist()\n",
    "        header_flag = True\n",
    "\n",
    "        for inchikey in inchikeys:\n",
    "            target_item_df = cleaned_df[cleaned_df['InChIKey:'] == inchikey].copy() #put all ms2 lists of one compound all in the target_item_df by inchikey separation\n",
    "            curr_precursormz = target_item_df.iloc[0]['MW:']  #\n",
    "            \n",
    "            raw_target_item_df = raw_df[raw_df['InChIKey:'] == inchikey].copy()\n",
    "            raw_target_item_df.sort_values(by=['NIST#:', 'MS2:'], inplace=True)\n",
    "            raw_target_item_s = raw_target_item_df.groupby(['NIST#:']).apply(retrieve_ms2_dict)\n",
    "            \n",
    "            raw_interfering_items_df = raw_df[raw_df['InChIKey:'] != inchikey]\n",
    "            raw_interfering_items_df = raw_interfering_items_df.append(raw_interfering_df, ignore_index=True)\n",
    "            raw_interfering_items_df = clean_MW(raw_interfering_items_df)\n",
    "            raw_interfering_items_df = raw_interfering_items_df[raw_interfering_items_df['MW:'] >= (curr_precursormz - 1)]\n",
    "            \n",
    "            if raw_interfering_items_df.shape[0] < 1:\n",
    "                target_item_df.to_csv(output_file, index=False)\n",
    "                break\n",
    "                \n",
    "            raw_interfering_items_df.sort_values(by=['NIST#:', 'MS2:'], inplace=True)\n",
    "            raw_interfering_items_s = raw_interfering_items_df.groupby(['NIST#:']).apply(retrieve_ms2_dict)\n",
    "\n",
    "            target_ms2_array = target_item_df['MS2:'].array\n",
    "            output_dict = {}\n",
    "            \n",
    "            \n",
    "            #add notes on the TP, TN for the explaination\n",
    "            # True positive means the selected ms2 from one compound ms2 list belongs to the compound\n",
    "            # True negative means the selected ms2 does not appears on the interfering compound ms2 list\n",
    "            # False positive means the selected ms2 appears on the interfering compound ms2 list\n",
    "            # False negative means the selected ms2 does not inside the selected compounds ms2 lists\n",
    "            \n",
    "            # Calculate TP, FN\n",
    "            for ms2 in target_ms2_array:\n",
    "                TP, FN = 0, 0\n",
    "                for i, ms2_dict in raw_target_item_s.iteritems():\n",
    "                    FN_flag = True\n",
    "                    \n",
    "                    if (ms2 - max(ms2_dict.keys())) > 0.7:\n",
    "                        FN += 1\n",
    "                        continue\n",
    "                        \n",
    "                    for key in ms2_dict.keys():\n",
    "                        diff = round(ms2 - key, 2)\n",
    "                        if abs(diff) <= search_range:\n",
    "                            FN_flag = False\n",
    "                            TP += 1\n",
    "                        elif diff < 0:\n",
    "                            if (FN_flag):\n",
    "                                FN += 1\n",
    "                            break\n",
    "                \n",
    "                output_dict[ms2] = {\n",
    "                    'TP': TP,\n",
    "                    'FN': FN\n",
    "                }\n",
    "# ====================================================================================================================== #\n",
    "            # Calculate FP, TN\n",
    "            for ms2 in target_ms2_array:\n",
    "                FP, TN = 0, 0\n",
    "                for i, ms2_dict in raw_interfering_items_s.iteritems():\n",
    "                    TN_flag = True\n",
    "                    \n",
    "                    if (ms2 - max(ms2_dict.keys())) > 0.7:\n",
    "                        TN += 1\n",
    "                        continue\n",
    "                        \n",
    "                    for key in ms2_dict.keys():\n",
    "                        diff = round(ms2 - key, 2)\n",
    "                        if abs(diff) <= search_range:\n",
    "                            TN_flag = False\n",
    "                            FP += 1\n",
    "                        elif diff < 0:\n",
    "                            if (TN_flag):\n",
    "                                TN += 1\n",
    "                            break\n",
    "                \n",
    "                output_dict[ms2]['FP'] = FP\n",
    "                output_dict[ms2]['TN'] = TN\n",
    "                \n",
    "                TP = output_dict[ms2]['TP']\n",
    "                FN = output_dict[ms2]['FN']\n",
    "                output_dict[ms2]['Accuracy'] = (TP+TN) / (TP+TN+FP+FN)\n",
    "                output_dict[ms2]['Sensitivity'] = TP / (TP+FN)\n",
    "                output_dict[ms2]['Specificity'] = TN / (FP+TN)\n",
    "\n",
    "            output_df = pd.DataFrame.from_dict(output_dict, orient='index')\n",
    "            output_df = target_item_df.join(output_df, on='MS2:')\n",
    "\n",
    "            output_df.sort_values(by=['Specificity'], inplace=True)\n",
    "            output_df.to_csv(output_file, index=False, mode='a', header=header_flag)\n",
    "            header_flag = False # only include header for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all output into same csv file\n",
    "\n",
    "read_folder = os.path.join(os.getcwd(), algo_3_output_folder, 'non_combined_output')\n",
    "output_folder = os.path.join(os.getcwd(), algo_3_output_folder)\n",
    "cwd = os.getcwd()\n",
    "os.chdir(read_folder)\n",
    "listdir = glob.glob('*.csv')\n",
    "os.chdir(cwd)\n",
    "\n",
    "output_filename = os.path.join(output_folder, 'combined_output_algo_3.csv')\n",
    "\n",
    "combined_csv = pd.concat([ pd.read_csv(os.path.join(read_folder, f)) for f in tqdm(listdir) ], ignore_index=True, sort=False)\n",
    "combined_csv.to_csv(output_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
